#### 设计

- **字段类型选择**，整型 > date,time > enum,char>varchar > blob。优先选择数字，二进制类型，再到字符类型。因为在对数据进行比较，排序等操作时，数字、二进制效率比字符类型高，字符类型需要按排序规则进行比较。其次字符集占用更多磁盘，mysql数据处理以页为单位，1页16k，每页能容纳的数据更多，处理效率更高，数字，二进制类型更能减少磁盘Io。
- 避免使用NULL，不利于索引，需要特殊标记，磁盘占用空间实际更大。
- 主键索引名为 pk_字段名；唯一索引名为 uk_字段名；普通索引名则为 idx_字段名。 说明：pk_ 即 primary key；uk_ 即 unique key；idx_ 即 index 的简称。
- 如果存储的字符串长度几乎相等，使用 char 定长字符串类型。
- varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度 大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效 率。

#### 索引

- 索引是帮助mysql高效获取数据的**排好序的数据结构**

##### 为什么选用b+树？

- mysql选用b+树组装存储数据，是因为b+树相对红黑树、b树矮状，每页不存储数据，只记录索引，这样每页能存储更多的索引信息，树高度更矮，遍历次数更少，叶子节点之间有双向指针，便于范围查询时取值。之所以不把所有索引放在同一叶，是因为一次io读取的数据有限，不可能一下把大量数据读到内存。

##### b+树的特点？

- 1.一个节点多个元素 2. 每个节点元素已排序 3. 叶子节点之间有指针 4. 非叶子节点冗余叶子节点索引数据。5. 非叶子节点不存储具体数据，数据存储在叶子节点。

##### myisam和innodb特点？

- myisam叶子节点存储，索引所在行的磁盘文件地址。（非聚集索引,数据和索引分开存储）
- innodb主键索引的叶子节点包含索引所在行的完整数据记录（聚集索引）
- innodb二级索引的叶子节点包含索引数据，和当前索引所在行的主键值。
- myisam在涉及大量数据的排序，全表扫描、count之类的操作时，比innodb有优势，因为索引所占用空间小，这些操作在内存中完成快。而且innodb需要维护mvcc。
- myisam适合读多写少，不需要事务支持的场景。比如省市县表。

##### innodb和myisam的区别？

- 1.b树叶子节点 2.锁的粒度 3.外键 4.事务 5.count

##### 为什么innodb推荐使用整型自增做主键?

- 因为innodb用b+树组织索引数据，自增主键便于B+树维护，b+树每叶的数据都是按顺序存放，整型便于排序，自增意味着新插入的数据只需插入到当前节点的下一个节点，每次插入不需要过度重新移动数据，效率更高。如果键的顺序经常无规则变化，一定会造成数据的迁移，带来IO性能上的损耗。

##### 索引优化建议，值得关注的？

- 利用联合索引(abc)检索时，即使中间b的索引断掉，mysql也能利用a索引找到叶子节点集合，然后再利用c索引排除不符合的数据，减少回表的次数（索引下推，mysql5.6后）。

- 联合索引最左列，选择区分度最高的。

- 更新频繁的字段，重复率大，text、image、bit等数据类型的字段不适合建索引；业务外键、频繁查询，频繁出现where条件中或连接子句的字段适合建立索引。

##### 不走索引的情况？
1.不符合最左原则 2.类型隐式转换 3.效率没有全表查询高(索引列使用函数，区分度不够大,not条件命中率低,连接字段类型不匹配)

##### sql技巧&索引优化

- 建立合适的索引，1:查询频繁 2:区分度高 3:长度小 4: 尽量能覆盖常用查询字段。索引长度直接影响索引文件的大小，需要在区分度+长度取得平衡。
- 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
- =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。
- 对于左前缀不易区分的列，比如网址开头都是www，可以倒过来存储建立索引。
- 在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据 实际文本区分度决定索引长度。索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达 90% 以上，可以使用 count(distinct left(列名, 索引长度))/count(*)的区分度来确定。
- **in子查询陷阱/坑**，就是in有时会被优化为exists执行，自行百度，5.5存在，5.6已优化。
- **大分页**，当自增主键完整，不存在物理删除时，可采用 `select id from 表 where id>5000000 limit 10;`或者**延迟关联**，子查询里利用索引查出相关数据的id，外层查询再关联子查询id直接获取完整数据。用在深度翻页，或者有模糊条件效率不高时。`SELECT t1.* FROM 表 1 as t1, (select id from 表 1 where 条件 LIMIT 100000,20 ) as t2 where t1.id=t2.id` 或者 `select t1.* from 表1 as t1 join (select id from 表1) as t2 on t1.id=t2.id`。
- 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。
- 在开启事务后，在事务内尽可能只操作数据库，并有意识地减少锁的持有时间（比如在事务内需要插入&&修改数据，那可以先插入后修改。因为修改是更新操作，会加行锁。如果先更新，那并发下可能会导致多个事务的请求等待行锁释放）
- 不要使用 count(列名)或 count(常量)来替代 count(*)，count(*)是 SQL92 定义的标 准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。
- 代码中写分页查询逻辑时，若 count 为 0 应直接返回，避免执行后面的分页语句。

##### 慢查询优化基本步骤

0. 先运行看看是否真的很慢，注意设置SQL_NO_CACHE

1. where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高

2. explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）

3. order by limit 形式的sql语句让排序的表优先查

4. 了解业务方使用场景

5. 加索引时参照建索引的几大原则

6. 观察结果，不符合预期继续从0分析

7. SQL 性能优化的目标：至少要达到 range 级别，要求是 ref 级别，如果可以是 consts 最好。

   > 说明： 
   >
   > 1） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。 
   >
   > 2） ref 指的是使用普通的索引（normal index）。 
   >
   > 3） range 对索引进行范围检索。 反例：explain 表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index 级别比较 range 还低，与全表扫描是小巫见大巫。


#### 事务

##### 事务的四个特征

- 原子性，要么一起成功要么一起失败。(redolog与undolog作基础)
- 隔离性，事务之间修改数据不会互相影响。(mvcc、临建锁)
- 持久性，一旦提交，永久落盘。(redolog作基础)
- 一致性，事务执行前执行后，数据一致。（以上共同保证）

##### 并发事务处理带来的问题

- 更新丢失：两个事务同时操作相同的数据，后提交的事务会覆盖先提交的事务处理结果，通过乐观锁就可以解决。

- 脏读：事务A读取到了事务B已经修改但尚未提交的数据，如果B事务回滚，A读取的数据无效，不符合一致性。

- 不可重复读：事务A读取到了事务B已经提交的数据，不符合隔离性。

- 幻读：事务A读取到了事务B提交的新增数据，不符合隔离性。（mvcc快照或行锁+间隙锁解决）

  | 隔离级别   | 脏读 | 不可重复读 | 幻读 |
  | ---------- | ---- | ---------- | ---- |
  | 读取未提交 | √    | √          | √    |
  | 读取已提交 | ×    | √          | √    |
  | 可重复读   | ×    | ×          | √    |
  | 可串行化   | ×    | ×          | ×    |

  innodb可重复读级别下，脏读、不可重复读不可能发生，幻读可能发生，要看具体情况。事务开启后，快照读(普通的select语句)后，会创建一张快照，之后数据根据这个快照(undolog)获取，不会发生幻读。如果在快照读后又进行了当前读(加锁)，如`select``...lock ``in share mode`、`select``...``for` 、`update，delete`等语句，会刷新快照。同时有别的事务创建数据，会包含在 新快照内，发生幻读。

#### mvcc

- 多版本并发控制，为了不加锁实现高并发的数据访问，对数据进行多版本处理，通过事务可见性保证事务能看到自己应该看到的数据版本，基于undolog，老版本数据写入undolog，定期清楚非活跃事务的undolog。
- 在读以提交和可重复读隔离级别下，开启事务后，mysql在第一次查询后会生成数据快照(读视图readview)，同个事务之后多次同样的查询结果都是基于当前快照，避免出现不可重复读，幻读等情况，保证了事务的隔离性，同时不会阻塞另一个事务对数据的写，提高Mysql事务的并发性。
  - **工作原理**，两个比较重要的功能，版本链和读视图。每行记录有两个隐藏字段，事务ID，保存该记录最后修改时操作事务的事务id(事务ID再执行update,delete语句时生成)，还有一个指向undolog的回滚指针，指向undolog记录的上个版本信息，窜连起来形成一个undolog版本链。
  - 事务开启后，第一次读会产生一个读视图，读视图保存当前事务ID，当前活跃事务ID集合，当前最小活跃事务ID和当前最大事务ID。
  - 第二次读时，读到的所有数据会拿数据修改的事务ID会和读视图版本进行一个对比
    - 修改事务ID等于读视图记录的当前事务ID，说明数据是自己修改的，可以获取。
    - 修改事务ID小于我们读视图的最小事务ID，说明在我们之前读的时候事务已经提交了，当前视图可以获取这些数据。
    - 如果修改事务id数据的事务ID是之前记录的活跃事务id，或者大于之前视图保存的最大事务ID，说明视图创建时，数据的事务还没有提交，这时需要根据undolog回滚指针回滚，直到符合视图可见的一个版本。
  - rc（读以提交）级别，每次读取都会生成读视图，rr（可重复读）级别第一次查询会产生读视图。


#### 锁

- select语句不加锁
- 开启事务后，`select ...lock in share mode`加共享锁，只允许读，不允许写被上锁的数据。
- 开启事务后，`select ...for update`、`update...`、`insert...`、`delete...`加排他锁，不允许读写。 
- **死锁**，并行执行的多个事务相互之间占有了对方所需要的资源。比如：事务A修改a行数据，事务B修改b行数据，然后事务A又修改b行数据，事务B又修改a行数据。此时，互相持有资源，互相阻塞等待直至超时，死锁。可以通过sql或者日志查看死锁情况。
- 按粒度细分的话有，行级锁、表级锁、页级锁(介于表锁与行锁之间)、记录锁(具体行)、间隙锁(某个范围)、临建锁(next-key lock 查出来的数据及他们之间的间隙范围)。

#### buffer pool

- 可以把buffer pool理解成一个大数组，一个元素对应着一页数据。
  - **free链表**，记录未被使用的内存。
  - **flush链表**，记录有变更但未落盘的脏页，有个线程负责把该链表的数据落盘
  - **lru链表**，管理数据淘汰用。5/8用以存储热数据，3/8用以存储冷数据。新查询的数据页会被放到冷数据头部，如果1秒后再次被查询，那么将移动到热数据区(之所以1秒后，是因为一个数据页可能存在多条记录，全表扫描时可能会重复遍历，所以大于1秒后再次访问才移动到热数据)。当free链表没有元素时，会把lru链表冷数据区最后一个元素指向的数据页淘汰掉，用以存储新的缓存。

#### wal

- mysql通过预写日志(binlog+redolog)再落盘，提高并发能力，保证数据不丢失。
- 为什么不直接落盘？因为要落盘的数据页不一定是顺序存储的，直接落盘有可能会随机io，性能比较差，写redolog不需要判断数据该存在哪，直接追加到redolog文件末尾，属于顺序写，效率高。后续再异步落盘。
- 开启事务后，执行update,delete,ddl等语句时，会生成一个redolog对象，叫做log buffer和buffer pool同级。事务提交后，会把log buffer直接落盘，或者写入操作系统文件缓存（看redolog持久化策略）。

##### redolog

- innodb引擎层日志，确保事务持久性，物理记录数据行具体修改值。宕机恢复事务。

- **redolog持久化策略**，innodb_flush_log_at_trx_commit，有三个参数

  - 1，默认值。事务每次提交都进行redolog文件写入。宕机不会丢失事务。性能较差。
  - 0，事务每次提交只创建log buffer缓存，每隔1秒后台线程写入系统文件缓存，并刷新落盘。宕机丢失1秒事务。性能好。
  - 2，事务提交会把数据写入文件系统缓存，由系统决定落盘时机，mysql服务挂掉，服务器没宕机不丢失事务。服务器宕机丢失大概1秒(?)事务。

  redolog为了利用内存，日志文件不只一个，多个文件构成一个文件组，循环写入。1个写满，会写到另外一个，当都写满了，又会从第一个文件重新写入。重新回到第一个文件写入时，如果文件中还存在未被落盘的数据，会暂停写入，执行落盘。所以可以多设置几个redolog文件，降低redolog落盘频率，提高性能，redolog文件数多，mysql重启回复会更慢。

##### binlog

- mysql 服务层，逻辑日志，记录sql执行语句。用以数据备份，主从配置。

- 日志格式，binlog_format，三个参数

  - **statement**，记录sql原文，但是有个问题，`update_time=now()`这里会获取当前系统时间，直接执行会导致与原库的数据不一致。
  - **row**，记录的内容不再是简单的`SQL`语句了，还包含操作的具体数据，比如update_time=now()变成了具体的时间update_time=1627112756247，是这种格式，需要更大的容量来记录，比较占用空间，恢复与同步时会更消耗`IO`资源，影响执行速度。
  - **mixed**，折中的方案，`MySQL`会判断这条`SQL`语句是否可能引起数据不一致，如果是，就用`row`格式，否则就用`statement`格式。
  - 值得注意，rc隔离级别，bin日志不能设置为statement，否则会出现Binlog与数据库数据不一致情况，具体自行百度。

- 刷盘时机，sync_binlog，三个参数，默认0

  - 为`0`的时候，表示每次提交事务都只`write`系统缓存，由系统自行判断什么时候执行`fsync`。系统宕机丢失数据。
  - `1`，表示每次提交事务都会执行`fsync`，不会丢失数据。
  - 还有一种折中方式，可以设置为`N(N>1)`，表示每次提交事务都`write`，但累积`N`个事务后才`fsync`。可以提升性能，但系统宕机会丢失N个事务。

##### redolog两阶段提交

- 为了保证binlog和redolog数据一致性，redolog采用两阶段提交，将`redo log`的写入拆成了两个步骤`prepare`和`commit`
- 使用**两阶段提交**后，写入`binlog`时发生异常也不会有影响，因为`MySQL`根据`redo log`日志恢复数据时，发现`redo log`还处于`prepare`阶段，并且没有对应`binlog`日志，就会回滚该事务。
- `redo log`设置`commit`阶段发生异常，不会回滚事务，虽然`redo log`是处于`prepare`阶段，但是能通过事务`id`找到对应的`binlog`日志，所以`MySQL`认为是完整的，就会提交事务恢复数据。

##### undolog

- 确保事务原子性，存在全局变量中，提供运行时的回滚和宕机恢复没关系。**主要记录了数据的逻辑变化**，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。
- undo log保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。
- undolog只记录活跃事务，当事务提交落盘后，undolog清除相关事务数据。

##### redolog、undolog、binlog落盘时机

- [undolog(内存)->redolog(prepare,已经物理刷盘)->binlog->redolog(commit)](https://zhuanlan.zhihu.com/p/410270379)



