##### redis 是线程还是多线程？

- 6.0之前，是单线程的。
- 6.0之后，网络io采用了多线程，键值读写依旧是单线程，并发安全。
- 不管6.0前还是6.0后，持久化和集群同步等，都是由额外线程执行。

##### redis 怎么实现一把分布式锁?

```shell
#ex设置过期时间，避免宕机死锁，nx表示只有key不存在时才写入
set test '随机' ex 10 nx
返回ok表示拿到锁，可以往下执行逻辑,返回nil表示锁被其他线程拿到，不往下执行逻辑

#代码逻辑...如果代码逻辑比较长，需要开一个线程给锁续命，确保业务周期内锁存在

#逻辑执行完后，删除锁。
if (get test) == '随机' {	#避免删除他人的锁，删除锁前要判断是否是自己的锁
	delete test
}
```

##### redis 单线程为什么还这么快？

- 基于内存操作
- 单线程，没有线程切换开销
- epoll提升io利用率
- 高效的数据结构，全局hash表，跳表，压缩列表，链表等等。

##### 缓存穿透

- 缓存层和数据层都没有数据

- 解决

  缓存空值

  布隆过滤器

##### 缓存雪崩

- 大批缓存同时失效，导致大量请求直接打到数据库

- 解决

  缓存时间加上一个随机值

  服务降级

  脚本维护缓存层

##### 缓存击穿

- 缓存雪崩是大规模的key失效，而缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。
- 解决：第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量（使用互斥锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。）

##### mysql、redis双写一致性

- 延时双删
- 缓存双写+mysql行锁
- 消息队列最终一致性

##### key 过期了，为什么内存没有释放？

redis key过期有两种删除策略
- 惰性删除：当读/写一个已经过期的key时，会触发惰性删除策略，判断key是否过期，如果过期了删掉这个key
- 定时删除：由于惰性删除策略，无法保证冷数据被即时删掉，redis会定期(默认每100ms)主动淘汰一批已经过期的key，这 里的一批只是部分过期key，所以可能会出现部分key已经过期但还没有清理掉的情况，导致内存没有被即使释放。

##### key 没设置过期时间，为什么被redis主动删除了？

当redis已用内存超过maxmemory限定时，触发主动清理策略，4.0之前实现了6中内存淘汰策略，4.0之后又增加了2中内存淘汰策略，总共8种：

- 针对设置了过期时间的key做处理：

  - volatile-lru，针对设置了过期时间的key，使用lru算法进行淘汰。
  - volatile-ttl，针对设置了过期时间的key，越早过期的越先被淘汰。
  - volatile-random，从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。
  - volatile-lfu，针对设置了过期时间的key，使用lfu算法进行淘汰。(新增)

- 针对所有的key做处理：

  - allkeys-lru，针对所有key使用lru算法进行淘汰。
  - allkeys-lfu，针对所有key使用lfu算法进行淘汰。（新增）
  - allkeys-random，针对所有的key使用随机淘汰机制进行淘汰。

- 不处理(默认)

  noeviction，不会淘汰任何数据，当使用的内存空间超过 maxmemory 值时，再有写请求来时返回错误。

##### redis淘汰key的算法LRU与LFU区别

LRU算法(最近最少使用)：淘汰很久没被访问过的数据，以最近一次访问时间作为参考。

LFU算法(最不经常使用)：淘汰最近一段时间被访问次数最少的数据，以次数作为参考，绝大多数情况我们都可以用LRU策略，当存在大量的热点缓存数据时，LFU可能更好点。

##### 删除key的命令会阻塞redis么？

会，O(n)，N为被删除的key数量

单个字符，时间复杂度O(1)

删除列表、集合、有序集合、哈希表的key，时间复杂度O(M)，M为以上数据结构内元素的数量。

##### rdb快照

默认开启，后台fork子进程异步持久化，新的命令在master和子进程双写，子进程dump完新的rdb文件会覆盖老快照。

```shell
默认配置：
save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存
save 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存
save 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存
```

rdb快照是二进制，恢复快。

##### aof持久化

默认关闭，aof日志记录redis命令，有三种持久化策略

- always：每次有新命令追加到AOF文件时就执行fsync，非常慢，也非常安全。
- everysec：每秒fsync一次，足够快，并且在故障时只会丢失1秒钟的数据。
- no ：从不fsync，数据写入os cache就撒手不管了，然后后面os自己会时不时有自己的策略将数据刷入磁盘，不可控了。更快，也更不安全的选择。

**aof重写**

是指把内存中的数据,逆化成命令,写入到.aof日志里.以解决 aof日志过大的问题.

```shell
#aof文件至少要达到64M才会自动重写，文件太小恢复速度本来就很快，重写意义不大
auto-aof-rewrite-min-size 64mb

#aof文件自从上一次文件重写后，文件大小增加了100%则再次触发重写
auto-aof-rewrite-percentage 100
```

##### 恢复时rdb和aof哪个恢复的快?

rdb快,因为其是数据的内存映射,直接载入到内存,而aof是命令,需要逐条执行

##### rdb和aof同时工作

1. 如果RDB在执行snapshotting操作，那么redis不会执行AOF rewrite; 如果redis再执行AOF rewrite，那么就不会执行RDB snapshotting
2. 如果RDB在执行snapshotting，此时用户执行BGREWRITEAOF命令，那么等RDB快照生成之后，才会去执行AOF rewrite
3. 同时有RDB snapshot文件和AOF日志文件，那么redis重启的时候，会优先使用AOF进行数据恢复，因为其中的日志更完整

##### redis4.0 混合持久化

混合持久化，正常记录aof，但在aof重写时，将这一刻内存做rdb快照处理+增量aof修改命令存在一起，写入新的文件，完成后替换旧aof文件。redis重启时，先加载rdb内容，再重放aof日志。混合持久化，兼具aof安全，rdb快速启动特性。

```shell
#必须先开启aof
aof-use-rdb-preamble yes
```

使用这种方式持久化，可以关掉rdb。

##### 一次线上事故，Redis主节点宕机导致数据全部丢失

- 哨兵部署示例；master没有开启数据持久化；redis进程用spervisor管理，并配置为进程宕机，自动重启；此时master宕机，哨兵还未发起切换，master进程立即被spervisor自动拉起，因为master没有配置持久化，启动后是个空实例，slave同步master也变成空实例，这种情况下数据全部丢失了。哨兵下，master不建议用spervisor管理。
- 主节点和从节点系统时间不一致，master挂掉，切换到slave，时间不一致导致缓存雪崩。

##### 主从复制风暴

如果redis有很多从节点，在某一时刻所有从节点同时链接主节点，那么主节点会同时把内存快照rdb发给多个从节点，导致主节点压力过大。

解决办法，从节点可以从别的从节点复制。

##### 数据双写不一致

针对修改的同一行数据加分布式锁。 或者mysql行锁。



##### redis底层设计

###### 全局hash表

- 数据用k,v形式组织，一个kv键值对叫Entry。
- 用一个全局数组管理Entry，叫hashtable。
- 每个Entry的key做 hash计算  % hashtable的长度 得到要数组下标，存储在hashtable对应下标处，值为一个指针，指向一个Entry，遇上hash冲突，会以单向链表组织Entry，新的元素放在链表头部。
- redis靠全局hash表查找key的速度近似O(1)。

###### hash表扩容

- 为了让哈希表的负载因子（load factor）维持在一个合理的范围内，会使用rehash（重新散列）操作对哈希表进行相应的扩展或收缩。每次插入键值对时，都会检查是否需要扩容。如果满足扩容条件，则进行扩容。**条件**：

  1）Redis服务器目前没有在执行BGSAVE(aof文件重写)命令或BGREWRITEAOF(生成RDB文件)命令，并且哈希表的负载因子大于等于1。

  2）Redis服务器目前在执行BGSAVE命令或BGREWRITEAOF命令，并且哈希表的负载因子大于等于5。

  负载因子=哈希表已保存节点数量 / 哈希表长度 load_factor = ht[0].used / ht[0].size

  当哈希表的负载因子小于0.1时，对哈希表执行收缩操作。
  
- **过程**

  [看这个](https://blog.csdn.net/belalds/article/details/93713491?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~sobaiduend~default-1-93713491.nonecase&utm_term=redis%E5%AD%97%E5%85%B8%E6%89%A9%E5%AE%B9%E7%9A%84%E6%9D%A1%E4%BB%B6&spm=1000.2123.3001.4430)

  我自己的理解：

  1. 创建个新的hashtable，长度是旧的2倍(不确定，有具体公式)，此时同时存在新旧两个hashtable。

  2. 旧的哈希表元素重新hash计算迁移到新的哈希表。这个过程叫做rehash。

  3. rehash的有2种方式，一种主动，一种被动。

     主动，访问(get&set)哈希表的时候进行rehash，一次迁移1个hash槽。一个hash槽可能是由链表组织的多个元素

     被动，redis事件轮询的时候也会rehash，默认迁移100个hash槽。

  4. rehash中，访问数据先访问旧的哈希表，不存在，再尝试访问新的哈希表。如果是加入新的元素，优先放到新的哈希表中。

  5. 这个过程就叫渐进式扩容。
